{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import wraps\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_iris\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Importiere MINST Daten\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/', one_hot=True)\n",
    "\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "#(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#mint=tf.keras.datasets.mnist\n",
    "#(x_,y_),(x_1,y_1)=mint.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Format\n",
    "\n",
    "Die Daten sind im Vektor Format gespeichert, obwohl die Originaldaten eine 2-dimensionale Matrix waren, die angab, wie viele Pigmente sich an welcher Position befinden. Untersuchen wir das genauer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.test.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen generieren und Accuracy auswerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verarbeiten der Daten\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reservieren 10.000 Samples zur Validierung\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.3466 - sparse_categorical_accuracy: 0.9029 - val_loss: 0.1751 - val_sparse_categorical_accuracy: 0.9509\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 7s 138us/sample - loss: 0.1577 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9626\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logger(orig_func):\n",
    "    import logging\n",
    "    logging.basicConfig(filename='Testdatenfile.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        #logging.info('Ran with args: {}'.format(args))\n",
    "        logging.info(orig_func(*args))\n",
    "        return orig_func(*args)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "    import logging\n",
    "    logging.basicConfig(filename='Testdatenfile.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        logging.info('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_logger\n",
    "@my_timer\n",
    "def fit(x_train, y_train): \n",
    "    return model.fit(x_train, y_train)\n",
    "    \n",
    "@my_logger\n",
    "@my_timer\n",
    "def predict(x_test):\n",
    "    return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 173us/sample - loss: 0.3016 - sparse_categorical_accuracy: 0.9133\n",
      "fit ran in: 8.655128717422485 sec\n",
      "50000/50000 [==============================] - 9s 183us/sample - loss: 0.1425 - sparse_categorical_accuracy: 0.9574\n",
      "fit ran in: 9.135992050170898 sec\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7fb001527090>\n",
      "predict ran in: 0.28151822090148926 sec\n",
      "predict ran in: 0.31096410751342773 sec\n",
      "[[6.14702600e-09 7.50709805e-09 1.06676980e-05 ... 9.99921441e-01\n",
      "  7.22658001e-07 6.13122756e-06]\n",
      " [1.41714040e-07 2.41886892e-06 9.99968886e-01 ... 6.32140282e-13\n",
      "  1.12440762e-06 1.15843880e-11]\n",
      " [2.38624784e-06 9.98613358e-01 8.35081097e-04 ... 2.87782110e-04\n",
      "  1.09913686e-04 1.39313106e-05]\n",
      " ...\n",
      " [5.56173857e-12 1.31396438e-09 2.08277201e-10 ... 1.79586863e-07\n",
      "  4.72318152e-06 5.08616446e-04]\n",
      " [6.07364612e-08 5.26258255e-08 1.46197263e-10 ... 8.63720118e-08\n",
      "  1.82177519e-05 2.50953391e-09]\n",
      " [8.20112177e-07 1.59678416e-11 8.68839081e-08 ... 1.89171359e-10\n",
      "  2.79791723e-09 8.33080605e-10]]\n"
     ]
    }
   ],
   "source": [
    "print(fit(x_train, y_train))\n",
    "\n",
    "print(predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnist.train.images[0]\n",
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb01b447ed0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "Wir werden 4 Parameter definieren müssen. Es ist wirklich (wirklich) schwer gute Parameterwerte für einen Datensatz zu bestimmen, mit dem man keine Erfahrung hat. Da dieser MNIST Datensatz allerdings so berühmt ist haben wir schon einige Ausgangswerte. Die Parameter sind:\n",
    "\n",
    "* Learning Rate - Wie schnell die Kostenfunktion angepasst wird\n",
    "* Traing Epochs - Wie viele Trainingszyklen durchlaufen werden sollen\n",
    "* Batch Size - Größe der \"Batches\" an Traingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netzwerk Parameter\n",
    "\n",
    "Hier haben wir Parameter welche unser Neuronales Netz direkt definieren. Diese werden entsprechend der betrachteten Daten angepasst und hängen auch davon ab, welche Art von Netz man nutzt. Es sind bis zu diesem Punkt erst einmal nur Zahlen, die wir später verwenden, um unser Netz zu definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Netzwerk Parameter\n",
    "n_hidden_1 = 256 # 1. Layer: Anzahl an Features\n",
    "n_hidden_2 = 256 # 2. Layer: Anzahl an Features\n",
    "n_input = 784 # MNIST Daten Input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST Klassen (0-9 Zahlen)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Modell\n",
    "\n",
    "Es ist Zeit unser Modell zu erstellen. Wiederholen wir deshalb kurz, was wir erstellen wollen:\n",
    "\n",
    "Zuerst erhalten wir einen *Input* in Form eines Datenarrays und schicken diesen an die erste *Hidden Layer*. Dann wird den Daten ein  *Weight* zwischen den Schichten zugewiesen (welches zuerst ein zufälliger Wert ist). Anschließend wird es an einen *Node* geschicht und unterläuft eine *Activation Function* (zusammen mit einem Bias, wie in der Neural Network Lektion erwähnt). Dann geht es weiter zur nächsten *Layer* und immer so weiter, bis zur finalen *Output Layer*. In unserem Fall werden wir nur 2 *Hidden Layers* verwenden. Je mehr wir davon verwenden, desto länger braucht das Modell (aber er hat mehr Möglichkeiten um die Genauigkeit zu erhöhen).\n",
    "\n",
    "Sobald die transformierte Daten die *Output Layer* erreicht haben müssen wir sie auswerten. Hier verwenden wir eine *Loss Function* (auch Cost Function genannt). Diese berechnet, wie sehr wir vom gewünschten Ergebnis entfernt sind. In diesem Fall: Wie viele der Klassen wir richtig zugeteilt haben.\n",
    "\n",
    "Dann wenden wir eine Optimierungsfunktion an, um die *Costs* (bzw. den Error) zu minimieren. Dies geschiet durch die Anpassung der *Weights* entlang des Netzes. Wir verwenden in unserem Beispiel den [Adam Optimizer](https://arxiv.org/pdf/1412.6980v8.pdf), welcher eine (im Vergleich zu anderen) sehr neue Entwicklung ist.\n",
    "\n",
    "Wir können anpassen, wie schnell diese Optimierung angewendet wird, indem wir unseren *Learning Rate* Parameter anpassen. Je geringer die Rate, desto höher die Möglichkeiten für Anpassungen. Dies erzeugt allerdings die Kosten einer erhöhten Wartezeit. Ab einem bestimmten Punkt lohnt es sich nicht mehr, die Learning Rate weiter zu senken.\n",
    "\n",
    "Jetzt können wir unser Modell erstellen. Wir beginnen mit 2 Hidden Layers, welche die []() Activation Function verwenden. Dies ist eine einfache Umformungsfunktion, die entweder x oder 0 zurückgibt. Für unsere finale Output Layer verwenden wir eine lineare Activation mit Matrixmultiplikation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Platzhalter für den Dateninput\n",
    "    weights: Dictionary der Weights\n",
    "    biases: Dictionary Der Biases\n",
    "    '''\n",
    "    # Erste Hidden layer mit RELU Activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Zweite Hidden layer mit RELU Activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Letzte Output layer mit linearer Activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights und Bias\n",
    "\n",
    "Damit unser Tensorflow Modell funktioniert müssen wir zwei Dictionaries anlegen, die unsere Weights und Biases enthalten. Wir können das `tf.variable` Objekt verwenden. Dies ist anders als eine Konstante, da Tensorflow's Graph Objekt alle Zustände der Variablen wahrnimmt. Eine Variable ist ein anpassbares Tensor, der zwischen Tensorflow's Graph von interagierenden Operationen lebt. Er kann durch die Berechnung verwendet und verändert werden. Wir werden die Modell Parameter generell als Variablen verwenden. Aus der Dokumentation können wir entnehmen:\n",
    "\n",
    "    A variable maintains state in the graph across calls to `run()`. You add a variable to the graph by constructing an instance of the class `Variable`.\n",
    "\n",
    "    The `Variable()` constructor requires an initial value for the variable, which can be a `Tensor` of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.\n",
    "    \n",
    "Wir werden Tensorflow's eingebaute `random_normal` Methode verwenden, um zufällige Werte für unsere Weights und Biases zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model erstellen\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost und Optimierungs-Funktion\n",
    "\n",
    "Wir verwenden Tensorflow's eingebaute Funktionen für diesesn Teil. Weitere Details bietet die Dokumentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-34-df1ccdc4bb87>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cost und Optimierungsfunktion definieren\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisierung der Variablen\n",
    "\n",
    "Wir initialisieren nun alle tf.Variable Objekte die wir zuvor erstellt haben. Das wird das erste sein, dass wir ausführen, wenn wir unser Modell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Modell trainieren\n",
    "\n",
    "### next_batch()\n",
    "\n",
    "Bevor wir beginnen möchte ich eine weitere nützliche Funktion in unserem MNIST Datenobjekt abdecken, die `next_batch` heißt. Diese gibt ein Tupel in der Form (X,y) mit einem X Array der Daten und einem y Array der Klasse. Zum Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xsamp,ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0014c9bd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ysamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Session ausführen\n",
    "\n",
    "Jetzt ist es Zeit unsere Session auszuführen! Achte darauf wie wir zwei Schleifen verwenden. Die äußere, die die Epochs durchläuft, und die innere, die die Batches für jede Epoch des Trainings ausführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost=156.3522\n",
      "Epoch: 2 Cost=39.6765\n",
      "Epoch: 3 Cost=24.8954\n",
      "Epoch: 4 Cost=16.9705\n",
      "Epoch: 5 Cost=12.2810\n",
      "Epoch: 6 Cost=8.9474\n",
      "Epoch: 7 Cost=6.6063\n",
      "Epoch: 8 Cost=4.7982\n",
      "Epoch: 9 Cost=3.6315\n",
      "Epoch: 10 Cost=2.6642\n",
      "Epoch: 11 Cost=1.8760\n",
      "Epoch: 12 Cost=1.4825\n",
      "Epoch: 13 Cost=1.1503\n",
      "Epoch: 14 Cost=0.9515\n",
      "Epoch: 15 Cost=0.7768\n",
      "Modellierung ist beendet: 15 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# starte Session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Variablen initialisieren\n",
    "sess.run(init)\n",
    "\n",
    "# Training Epochs\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start mit cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Konvertiere die Anzahl an Batches in eine Integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Schleife für alle Batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Den nächsten Batch an Trainingsdaten und -lables nehmen\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Dictionary für Optimierung und Cost bereitstellen\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Durchschnittliche Kosten berechnen\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} Cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Modellierung ist beendet: {} Epochs of Training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell Auswertung\n",
    "\n",
    "Tensorflow bietet einige eingebaute Funktionen, die uns bei der Auswertung helfen. Dazu gehören `tf.equal` und `tf.reduce_mean`.\n",
    "\n",
    "\n",
    "### tf.equal\n",
    "\n",
    "Dies ist im Grunde genommen nur eine Kontrolle, ob die Vorhersagen mit den Labels übereinstimmen. Da wir in unserem Fall wissen, dass die Labels eine 1 in einem Array von Nullen sind, können wir `argmax()` verwenden, um die Position zu vergleichen. Denke daran, dass y immer noch der Platzhalter ist, den wir anfangs erstellt haben. Wir werden eine Reihe an Operationen durchführen, um einen Tensor zu erhalten, in den wir die Testdaten einlesen können, um es auszuwerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: [[0.06602337 0.10761142 0.09131734 ... 0.12323714 0.1011647  0.08715004]\n",
      " [0.095297   0.0753293  0.0542006  ... 0.10497974 0.09442706 0.07023755]\n",
      " [0.08915443 0.09313934 0.07622365 ... 0.08189514 0.10487104 0.07281642]\n",
      " ...\n",
      " [0.08235214 0.13055676 0.07968119 ... 0.06965394 0.10786705 0.06616671]\n",
      " [0.0614849  0.09460336 0.07588268 ... 0.08536131 0.10871477 0.09578106]\n",
      " [0.06368779 0.06781684 0.06343921 ... 0.07808332 0.12504216 0.05349719]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Teste das Modell\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "test_accuracy = model.predict(x_test)\n",
    "print()\n",
    "print('Test Accuracy:', test_accuracy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um numerische Werte für unsere Vorhersagen zu erhalten müssen wir `tf.cast` verwenden, um den Tensor mit Booleans zurückzuführen in einen Tensor mit Floats. Dann können wir den Durchschnitt nehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir `tf.reduce_mean` verwenden, um den Durchschnitt der Elemente im Tensor zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das wirkt evtl. etwas merkwürdig, aber diese Genauigkeit ist immer noch ein Tensor Objekt. Denke daran, dass wir immer noch die tatsächlichen Testdaten übergeben müssen. Jetzt können wir die MNIST Testlabels und Bilder aufrufen und die Genauigkeit auswerten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `eval()` Methode erlaubt es uns direkt in der Session den Tensor auszuwerten ohne `tf.sess():mm` aufrufen zu müssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9458\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94%! Nicht schlecht! Aber das ist noch lange nicht zu gut, wie wir es schaffen können. Mehr Trainingsdurchläuft (Epochs) mit diesen Daten (ca. 20000) können eine Genauigkeit von 99% erreichen. Da dies sehr lange dauert werden wir es hier nicht durchführen.\n",
    "\n",
    "# Gut gemacht!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
