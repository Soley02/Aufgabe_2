{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import wraps\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_iris\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen generieren und Accuracy auswerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verarbeiten der Daten\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float64\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float64\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float64\")\n",
    "y_test = y_test.astype(\"float64\")\n",
    "\n",
    "# Reservieren 10.000 Samples zur Validierung\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 17s 335us/sample - loss: 0.3369 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9489\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 10s 197us/sample - loss: 0.1605 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9617\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logger(orig_func):\n",
    "    import logging\n",
    "    logging.basicConfig(filename='log.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        #logging.info('Ran with args: {}'.format(args))\n",
    "        result = orig_func(*args)\n",
    "        logging.info(result)\n",
    "        return result\n",
    "    \n",
    "        #logging.info(orig_func(*args))\n",
    "        #return orig_func(*args)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "    import logging\n",
    "    logging.basicConfig(filename='log.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        logging.info('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 25s 510us/sample - loss: 0.1217 - sparse_categorical_accuracy: 0.9637\n",
      "fit ran in: 25.5206880569458 sec\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7faee8f013d0>\n",
      "predict ran in: 0.7236232757568359 sec\n",
      "[[1.2992699e-08 8.4826652e-09 7.2865980e-05 ... 9.9986470e-01\n",
      "  4.6642936e-07 5.8632459e-08]\n",
      " [4.8795238e-07 1.4217251e-06 9.9997962e-01 ... 1.6677680e-12\n",
      "  3.2323289e-08 2.5166028e-14]\n",
      " [9.7262373e-06 9.9530208e-01 1.8785631e-03 ... 8.8546914e-04\n",
      "  2.8884955e-04 9.7571001e-06]\n",
      " ...\n",
      " [2.6608125e-12 7.1791674e-12 1.4026950e-09 ... 2.8185261e-07\n",
      "  8.1118958e-07 6.5389331e-06]\n",
      " [5.6595257e-09 5.0138726e-12 4.2566978e-11 ... 5.2597503e-11\n",
      "  2.0208868e-06 2.1505096e-11]\n",
      " [3.9422187e-07 2.9639756e-12 6.9505468e-09 ... 1.4996459e-11\n",
      "  4.5615803e-11 6.4748935e-12]]\n"
     ]
    }
   ],
   "source": [
    "print(fit(x_train, y_train))\n",
    "\n",
    "print(predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object): \n",
    "    def normalize(self, x_train, x_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        x_train = self.scaler.fit_transform(x_train)\n",
    "        x_test  = self.scaler.transform(x_test)\n",
    "        return (x_train, x_test) \n",
    "    \n",
    "    def inverse(self, x_train, x_val, x_test):\n",
    "        x_train = self.scaler.inverse_transform(x_train)\n",
    "        x_test  = self.scaler.inverse_transform(x_test)\n",
    "        return (x_train, x_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "  \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):  \n",
    "      self.x_train, self.y_train, self.x_test, self.y_test = x_train, y_train, x_test, y_test    \n",
    "        \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def fit(self): \n",
    "        normalizer = Normalize()\n",
    "        self.x_train, self.x_test = normalizer.normalize(self.x_train, self.x_test)   \n",
    "        train_samples = self.x_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight='balanced',\n",
    "            )\n",
    "        self.classifier.fit(self.x_train, self.y_train)\n",
    "        self.train_y_predicted = self.classifier.predict(self.x_train)\n",
    "        self.train_accuracy = np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100\n",
    "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)        \n",
    "        return self.train_accuracy\n",
    "    \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def predict(self):\n",
    "        self.test_y_predicted = self.classifier.predict(self.x_test) \n",
    "        self.test_accuracy = np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100 \n",
    "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)        \n",
    "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
    "        print(\"Classification report for classifier:\\n %s\\n\" % (self.report))\n",
    "        return self.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setUp\n",
      "__init__ ran in: 4.291534423828125e-06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit ran in: 19.956449031829834 sec\n",
      "setUp\n",
      "__init__ ran in: 2.86102294921875e-06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit ran in: 21.153944969177246 sec\n",
      "Classification report for classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.94      0.85       980\n",
      "        1.0       0.76      0.96      0.85      1135\n",
      "        2.0       0.79      0.64      0.71      1032\n",
      "        3.0       0.67      0.76      0.71      1010\n",
      "        4.0       0.71      0.77      0.74       982\n",
      "        5.0       0.62      0.42      0.50       892\n",
      "        6.0       0.69      0.84      0.76       958\n",
      "        7.0       0.76      0.80      0.78      1028\n",
      "        8.0       0.79      0.59      0.67       974\n",
      "        9.0       0.78      0.58      0.66      1009\n",
      "\n",
      "avg / total       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "predict ran in: 0.18126606941223145 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_fit (__main__.TestInput)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-25-ca086a060c24>\", line 40, in test_fit\n",
      "    self.assertEqual(result, self.train_accuracy)\n",
      "AssertionError: 72.442 != 73.4\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_predict (__main__.TestInput)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-25-ca086a060c24>\", line 49, in test_predict\n",
      "    self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
      "AssertionError: 73.57000000000001 != 74\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 41.315s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import time\n",
    "\n",
    "class TestInput(unittest.TestCase):\n",
    "  \n",
    "    @classmethod\n",
    "    def setUpClass(cls):  \n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls): \n",
    "        pass\n",
    "\n",
    "    def setUp(self):\n",
    "        print('setUp') \n",
    "        #X, y = download()\n",
    "        #splitRatio = 60000\n",
    "        #self.X_train, self.y_train, self.X_test, self.y_test = split(X,y,splitRatio) \n",
    "        \n",
    "        self.train_accuracy = 72.442  # 73.44 fit()\n",
    "        \n",
    "        self.test_accuracy = 73.57000000000001  # 74 predict()\n",
    "        \n",
    "        self.train_runtime = 19\n",
    "        \n",
    "    def tearDown(self):\n",
    "        # print('tearDown')\n",
    "        pass\n",
    "        \n",
    "    def test_fit(self):     \n",
    "        np.random.seed(31337)\n",
    "        self.ta = TheAlgorithm(x_train, y_train, x_test, y_test)\n",
    "        \n",
    "        # Zeit messen\n",
    "        start_fit= time.time()\n",
    "        result = self.ta.fit()\n",
    "        duration_fit = time.time() - start_fit\n",
    "        \n",
    "        #self.assertEqual(self.ta.fit(), self.train_accuracy) \n",
    "        self.assertEqual(result, self.train_accuracy) \n",
    "        \n",
    "        #Zeit verifizieren < 120 %\n",
    "        self.assertLessEqual(duration_fit, 1.2 * 18)\n",
    "  \n",
    "    def test_predict(self):\n",
    "        np.random.seed(31337)\n",
    "        self.ta = TheAlgorithm(x_train, y_train, x_test, y_test)\n",
    "        self.ta.fit()\n",
    "        self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    #run tests \n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
