{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import wraps\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_iris\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen generieren und Accuracy auswerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verarbeiten der Daten\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float64\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float64\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float64\")\n",
    "y_test = y_test.astype(\"float64\")\n",
    "\n",
    "# Reservieren 10.000 Samples zur Validierung\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logger(orig_func):\n",
    "    import logging\n",
    "    logging.basicConfig(filename='log.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        #logging.info('Ran with args: {}'.format(args))\n",
    "        result = orig_func(*args)\n",
    "        logging.info(result)\n",
    "        return result\n",
    "    \n",
    "        #logging.info(orig_func(*args))\n",
    "        #return orig_func(*args)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "    import logging\n",
    "    logging.basicConfig(filename='log.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        logging.info('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit(x_train, y_train))\n",
    "\n",
    "print(predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object): \n",
    "    def normalize(self, x_train, x_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        x_train = self.scaler.fit_transform(x_train)\n",
    "        x_test  = self.scaler.transform(x_test)\n",
    "        return (x_train, x_test) \n",
    "    \n",
    "    def inverse(self, x_train, x_val, x_test):\n",
    "        x_train = self.scaler.inverse_transform(x_train)\n",
    "        x_test  = self.scaler.inverse_transform(x_test)\n",
    "        return (x_train, x_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "  \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):  \n",
    "      self.x_train, self.y_train, self.x_test, self.y_test = x_train, y_train, x_test, y_test    \n",
    "        \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def fit(self): \n",
    "        normalizer = Normalize()\n",
    "        self.x_train, self.x_test = normalizer.normalize(self.x_train, self.x_test)   \n",
    "        train_samples = self.x_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight='balanced',\n",
    "            )\n",
    "        self.classifier.fit(self.x_train, self.y_train)\n",
    "        self.train_y_predicted = self.classifier.predict(self.x_train)\n",
    "        self.train_accuracy = np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100\n",
    "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)        \n",
    "        return self.train_accuracy\n",
    "    \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def predict(self):\n",
    "        self.test_y_predicted = self.classifier.predict(self.x_test) \n",
    "        self.test_accuracy = np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100 \n",
    "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)        \n",
    "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
    "        print(\"Classification report for classifier:\\n %s\\n\" % (self.report))\n",
    "        return self.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import time\n",
    "\n",
    "class TestInput(unittest.TestCase):\n",
    "  \n",
    "    @classmethod\n",
    "    def setUpClass(cls):  \n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls): \n",
    "        pass\n",
    "\n",
    "    def setUp(self):\n",
    "        print('setUp') \n",
    "        #X, y = download()\n",
    "        #splitRatio = 60000\n",
    "        #self.X_train, self.y_train, self.X_test, self.y_test = split(X,y,splitRatio) \n",
    "        \n",
    "        self.train_accuracy = 72.442  # 73.44 fit()\n",
    "        \n",
    "        self.test_accuracy = 73.57000000000001  # 74 predict()\n",
    "        \n",
    "        self.train_runtime = 19\n",
    "        \n",
    "    def tearDown(self):\n",
    "        # print('tearDown')\n",
    "        pass\n",
    "        \n",
    "    def test_fit(self):     \n",
    "        np.random.seed(31337)\n",
    "        self.ta = TheAlgorithm(x_train, y_train, x_test, y_test)\n",
    "        \n",
    "        # Zeit messen\n",
    "        start_fit= time.time()\n",
    "        result = self.ta.fit()\n",
    "        duration_fit = time.time() - start_fit\n",
    "        \n",
    "        #self.assertEqual(self.ta.fit(), self.train_accuracy) \n",
    "        self.assertEqual(result, self.train_accuracy) \n",
    "        \n",
    "        #Zeit verifizieren < 120 %\n",
    "        self.assertLessEqual(duration_fit, 1.2 * 18)\n",
    "  \n",
    "    def test_predict(self):\n",
    "        np.random.seed(31337)\n",
    "        self.ta = TheAlgorithm(x_train, y_train, x_test, y_test)\n",
    "        self.ta.fit()\n",
    "        self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    #run tests \n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
